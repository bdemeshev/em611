\documentclass[12pt]{article} % размер шрифта

\usepackage{tikz} % картинки в tikz
\usepackage{microtype} % свешивание пунктуации

\usepackage{array} % для столбцов фиксированной ширины

\usepackage{url} % для вставки ссылок \url{...}

\usepackage{indentfirst} % отступ в первом параграфе

\usepackage{sectsty} % для центрирования названий частей
\allsectionsfont{\centering} % приказываем центрировать все sections

\usepackage{amsthm} % теоремы и доказательства

\theoremstyle{definition} % прямой шрифт в условии теорем
\newtheorem{theorem}{Теорема}[section]


\usepackage{amsmath, amssymb} % куча стандартных математических плюшек

\usepackage[top=2cm, left=1.5cm, right=1.5cm, bottom=2cm]{geometry} % размер текста на странице

\usepackage{lastpage} % чтобы узнать номер последней страницы

\usepackage{enumitem} % дополнительные плюшки для списков
%  например \begin{enumerate}[resume] позволяет продолжить нумерацию в новом списке
\usepackage{caption} % подписи к картинкам без плавающего окружения figure


\usepackage{fancyhdr} % весёлые колонтитулы
\pagestyle{fancy}
\lhead{Эконометрика, финтех}
\chead{}
\rhead{2019-12-23, Праздник}
\lfoot{}
\cfoot{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}



\usepackage{todonotes} % для вставки в документ заметок о том, что осталось сделать
% \todo{Здесь надо коэффициенты исправить}
% \missingfigure{Здесь будет картина Последний день Помпеи}
% команда \listoftodos — печатает все поставленные \todo'шки

\usepackage{booktabs} % красивые таблицы
% заповеди из документации:
% 1. Не используйте вертикальные линии
% 2. Не используйте двойные линии
% 3. Единицы измерения помещайте в шапку таблицы
% 4. Не сокращайте .1 вместо 0.1
% 5. Повторяющееся значение повторяйте, а не говорите "то же"

\usepackage{fontspec} % поддержка разных шрифтов
\usepackage{polyglossia} % поддержка разных языков

\setmainlanguage{russian}
\setotherlanguages{english}

\setmainfont{Linux Libertine O} % выбираем шрифт
% если Linux Libertine не установлен, то
% можно также попробовать Helvetica, Arial, Cambria и т.Д.

% чтобы использовать шрифт Linux Libertine на личном компе,
% его надо предварительно скачать по ссылке
% http://www.linuxlibertine.org/index.php?id=91&L=1

% на сервисах типа sharelatex.com этот шрифт есть :)

\newfontfamily{\cyrillicfonttt}{Linux Libertine O}
% пояснение зачем нужно шаманство с \newfontfamily
% http://tex.stackexchange.com/questions/91507/

\AddEnumerateCounter{\asbuk}{\russian@alph}{щ} % для списков с русскими буквами
\setlist[enumerate, 2]{label=\asbuk*),ref=\asbuk*} % списки уровня 2 будут буквами а) б) ...

%% эконометрические и вероятностные сокращения
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\sCov}{sCov}
\DeclareMathOperator{\sCorr}{sCorr}
\DeclareMathOperator{\sVar}{sVar}
\DeclareMathOperator{\E}{E}
\def \hb{\hat{\beta}}
\def \hs{\hat{\sigma}}
\def \htheta{\hat{\theta}}
\def \s{\sigma}
\def \hy{\hat{y}}
\def \hY{\hat{Y}}
\def \v1{\vec{1}}
\def \e{\varepsilon}
\def \he{\hat{\e}}
\def \z{z}
\def \hVar{\widehat{\Var}}
\def \hCorr{\widehat{\Corr}}
\def \hCov{\widehat{\Cov}}
\def \cN{\mathcal{N}}


\begin{document}

\begin{enumerate}

\item Технические задачки :)

\begin{enumerate}
  \item Величины $X_1$, \ldots, $X_{10}$ независимы и равномерны на $[0;1]$. 
  Величины $Y_1$, \ldots, $Y_{10}$ — это отсортированные по возрастанию квадраты $X_i$. 
  В частности, $Y_1 = \min \{X_1^2, \ldots, X_{10}^2\}$, и $Y_{10} = \max \{X_1^2, \ldots, X_{10}^2\}$

  Выпишите совместную функцию плотности $Y_3$ и $Y_5$ в точке $(a, b)$.

  \item Компоненты двумерного вектора $X$ независимы и нормальны $\cN(0;1)$. 
  
  Как распределен квадрат косинуса угла между вектором и положительным направлением оси абсцисс?

  \item Компоненты четырёхмерного вектора $X$ независимы и нормальны $\cN(0;1)$. 
  Грета Тунберг выбрала в четырёхмерном пространстве два ортогональных двумерных плоскости. 
  Обозначим $L_1$ и $L_2$ — квадраты длин проекций вектора $X$ на эти две плоскости. 

  Как распределено отношение $L_1 / L_2$?
\end{enumerate}



\item Рассмотрим модель множественной регрессии, $y=X\beta + u$, где регрессоры детерминистические, а $u \sim \cN(0; \sigma^2 \cdot I)$.
Параметры $\beta$ и $\sigma^2$ неизвестны. Мы хотим проверить гипотезу $H_0$: $\sigma = 1$.


\begin{enumerate}
\item Выведите формулы для статистик $W$, $LR$, $LM$.
\item Сравните эти статистики между собой, если это возможно. 
\end{enumerate}


\item Найдите ожидаемую информацию Фишера:
\begin{enumerate}
  \item для классической множественной регрессии;
  \item для логистической регрессии; 
\end{enumerate}


\item Есть 101 наблюдение и три переменных: $x_i$, $y_i$ и $z_i$. 
Вектор выборочных средних равен $(0, 1, 2)^T$, 
обратная матрица к выборочной ковариационной матрице равна 

\[
\begin{pmatrix}
  10 & -1 & 6 \\
  -1 & 9 & 2 \\
  6  & 2 & 25 \\
\end{pmatrix}
\]

Найдите все коэффициенты в регрессии $y_i$ на $x_i$ и $z_i$ с константой. 

\newpage
\item Винни-Пух знает, что мёд бывает правильный, $honey_i=1$, и неправильный, $honey_i=0$. Пчёлы также бывают правильные, $bee_i=1$, и неправильные, $bee_i=0$. По 100 своим попыткам добыть мёд Винни-Пух составил таблицу сопряженности:

\begin{tabular}{c|cc}
\toprule
 & $honey_i=1$ & $honey_i=0$ \\
\midrule
$bee_i=1$ & 10 & 30 \\
$bee_i=0$ & 20 & 40 \\
\bottomrule
\end{tabular}

Винни-Пух использует логистическую регрессию с константой для прогнозирования правильности мёда с помощью правильности пчёл.

\begin{enumerate}
\item Какие оценки коэффициентов получит Винни-Пух?
\item Какой прогноз вероятности правильности мёда при встрече с неправильными пчёлами даёт логистическая модель? Как это число можно посчитать без рассчитывания коэффициентов?
\item Проверьте гипотезу о том, что правильность пчёл не оказывает влияние на правильность мёда с помощью тестов LR, LM и W.
\end{enumerate}


\item Как изменятся оценки МНК и классическая оценка ковариационной матрицы оценок МНК, 
если каждое наблюдение учесть два раза?


\item Предположим, что $y_i= \beta_1 + \beta_2 x_i + u_i$, наблюдения независимы и одинаково распределены, 
предпосылки теоремы Гаусса-Маркова выполнены.

Эконометрист Кирилл строит оценку коэффициентов следующим образом: через каждую пару точек проводит прямую, 
а затем усредняет угловые коэффициенты всех прямых (получает $\hat \beta_2$), 
усредняет точки пересечения с вертикальной осью всех прямых (получает $\hat \beta_1$).

Будут ли оценки Кирилла несмещёнными? Состоятельными? 



%   \item Рассмотрим модель множественной регрессии, $y=X\beta + u$, где регрессоры детерминистические, а $u \sim \cN(0; \sigma^2 \cdot I)$.
%   Величина $\sigma^2$ неизвестна и тоже оценивается.
%   Мы хотим проверить гипотезу $H_0$: $\beta = 0$.

%   \begin{enumerate}
%     \item Выведите формулы для статистик $W$, $LR$, $LM$.
%     \item Сравните эти статистики между собой.
%   \end{enumerate}

%   \item Сэр Томас Байес в 18 веке решил задачу, которая на современном языке
%   формулируется так:

%   Величина $R$ имеет равномерное распределение на отрезке $[0;1]$.
%   Мы изготавливаем монетку, выпадающую орлом с вероятностью $R$.
%   Затем подбрасываем её $n$ раз. Из этих $n$ раз оказывается $X$ орлов и
%   $Y$ решек.

% \begin{enumerate}
%     \item Как выглядит условная плотность величины $R$ при известных $X$ и $Y$ с точностью до константы?
%     \item Какова условная вероятность того, что монетка выпадет орлом, при известных $X$ и $Y$?
% \end{enumerate}

%   Хинт: какое там есть распределение-то на отрезке $[0;1]$?
%   А тут ещё две известных величины, $X$ и $Y$ завалялись :)

%   \item Вспомнив Матрицу-Мать-Всех-Регрессий, докажите, что
% в регрессии
% \[
% \hat y_i = \hat\beta_1 + \hat \beta_x x_i + \hat \beta_z z_i + \hat \beta_w w_i
% \]
% величину $R^2$ можно разложить в сумму:
% \[
% R^2 = \hat \beta_x \frac{\sCov(y, x)}{\sVar(y)} + \hat \beta_z \frac{\sCov(y, z)}{\sVar(y)} + \hat \beta_w \frac{\sCov(y, w)}{\sVar(y)}
% \]


%   \item Посмотрим, кто прорешал первую кр :)

%   Докажите, что в методе главных компонент с масштабированием переменных средняя величина $R^2$ по всем парным
%   регрессиям исходных переменных на первую главную компоненту равна наибольшему сингулярному значению
%   матрицы исходных переменных.


% \newpage


% \item Величины $U_1$ и $U_2$ независимы и равномерны $U[0;1]$. Рассмотрим пару величин $Y_1 = R\cdot \cos \alpha$, $Y_2 = R\cdot \sin \alpha$, где $R=\sqrt{-2\ln U_1}$, а $\alpha = 2\pi U_2$.
% \begin{enumerate}
%   \item Выпишите дифференциальную форму для пары $U_1$, $U_2$;
%   \item Выпишите дифференциальную форму для пары $Y_1$, $Y_2$;
%   \item  Найдите совместный закон распределения $Y_1$ и $Y_2$;
%   \item Верно ли, что $Y_1$ и $Y_2$ независимы?
%   \item  Как распределены $Y_1$ и $Y_2$ по отдельности?

% \end{enumerate}

%   \item Эта задача посвящена доказательству неравенства Крамера-Рао. Суть его в том, что если мы возьмём любую несмещённую оценку, то её дисперсия будет не меньше некоторой границы. А именно, если $\hat a$ — любая несмещённая оценка вектора $a$, то матрица $M$,
%   \[
%   M = \Var(s(a))\cdot \Var(\hat a) - I_{k\times k}
%   \]
%   неотрицательно определена. В этой задаче $\hat a$ — произвольная несмещённая оценка, не обязательно равная $\hat a_{ML}$!
%   Как обычно, $s(a)$ — градиент функции правдоподобия в истинной точке.

%     \begin{enumerate}
%       \item Вспомните, чему равно $\E(s(a))$.
%       \item Найдите скаляры $\Cov\left(\hat a_1, \frac{\partial \ell}{\partial a_1}\right)$,
% 	$\Cov\left(\hat a_1, \frac{\partial \ell}{\partial a_2}\right)$
% 	и матрицу $\Cov\left(\hat a, s(a) \right)$.
%       \item Рассмотрим два произвольных случайных вектора $r$ и $s$ и два вектора констант подходящей длины $\alpha$ и $\beta$.
% 	Найдите минимум функции $f(\alpha, \beta) = \Var(\alpha^T r + \beta^T s)$ по $\beta$.
% 	Выпишите явно $\beta^*(\alpha)$ и $f^*(\alpha)$.
%       \item Докажите, что для произвольных случайных векторов положительно определена матрица
% 	\[
%           \Var(r) - \Cov(r, s) \Var^{-1}(s)\Cov(s, r)
% 	\]
%       \item Завершите доказательство векторного неравенства Крамера-Рао.
%     \end{enumerate}




\end{enumerate}



\end{document}
